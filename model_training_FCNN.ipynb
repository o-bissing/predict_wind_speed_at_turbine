{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T18:09:42.603175600Z",
     "start_time": "2024-12-26T18:09:39.544454900Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "460cc4f5342e76a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T18:24:00.174505400Z",
     "start_time": "2024-12-26T18:23:59.208167400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train_data.csv')\n",
    "df_test = pd.read_csv('test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "200f29bc64cd27dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T18:25:25.210178500Z",
     "start_time": "2024-12-26T18:25:25.207673200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = df_train.iloc[:, :-1].values  # All columns except the last as features\n",
    "y_train = df_train.iloc[:, -1].values   # Last column as target\n",
    "X_test = df_test.iloc[:, 1:].values   # All columns except the first as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2ecf4d8e4c5734a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T18:25:26.659625Z",
     "start_time": "2024-12-26T18:25:26.583157700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a977cfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a directory for TensorBoard logs\n",
    "tensorboard_callback = TensorBoard(log_dir='D:\\\\Python\\\\TBlogs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f20d2fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the EarlyStopping callback\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # Metric to monitor\n",
    "    patience=30,         # Number of epochs to wait without improvement\n",
    "    restore_best_weights=True  # Restore the weights of the best epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ea3ea8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(learning_rate=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "82b0488e16aa75ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T18:13:45.169520100Z",
     "start_time": "2024-12-26T18:13:45.034463500Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_11\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_11\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,248</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_42 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_39 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m5,248\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_28 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_40 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_29 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_41 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_30 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_42 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,617</span> (61.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m15,617\u001b[0m (61.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,617</span> (61.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m15,617\u001b[0m (61.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the FCNN model\n",
    "model = Sequential([\n",
    "    Input(shape=(X_train.shape[1],)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='linear')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
    "\n",
    "# Model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a67c14d44de616c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T20:42:25.043735900Z",
     "start_time": "2024-12-26T20:35:01.514150100Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 12.0341 - mae: 2.5814 - val_loss: 1.2498 - val_mae: 0.8470\n",
      "Epoch 2/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 2.8576 - mae: 1.2881 - val_loss: 1.1001 - val_mae: 0.8088\n",
      "Epoch 3/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 2.2584 - mae: 1.1379 - val_loss: 0.9354 - val_mae: 0.7284\n",
      "Epoch 4/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 1.9554 - mae: 1.0498 - val_loss: 0.9101 - val_mae: 0.7117\n",
      "Epoch 5/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 1.7541 - mae: 0.9882 - val_loss: 0.7861 - val_mae: 0.6649\n",
      "Epoch 6/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 1.5628 - mae: 0.9344 - val_loss: 0.6614 - val_mae: 0.5940\n",
      "Epoch 7/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 1.4858 - mae: 0.9103 - val_loss: 0.6145 - val_mae: 0.5793\n",
      "Epoch 8/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 1.3917 - mae: 0.8790 - val_loss: 0.6034 - val_mae: 0.5789\n",
      "Epoch 9/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 1.3183 - mae: 0.8547 - val_loss: 0.5718 - val_mae: 0.5633\n",
      "Epoch 10/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 1.2895 - mae: 0.8451 - val_loss: 0.5288 - val_mae: 0.5436\n",
      "Epoch 11/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 1.2353 - mae: 0.8246 - val_loss: 0.5214 - val_mae: 0.5387\n",
      "Epoch 12/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 1.1800 - mae: 0.8073 - val_loss: 0.4979 - val_mae: 0.5210\n",
      "Epoch 13/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 1.1147 - mae: 0.7807 - val_loss: 0.5087 - val_mae: 0.5326\n",
      "Epoch 14/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 1.0826 - mae: 0.7715 - val_loss: 0.5005 - val_mae: 0.5271\n",
      "Epoch 15/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 1.0522 - mae: 0.7616 - val_loss: 0.5060 - val_mae: 0.5299\n",
      "Epoch 16/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 1.0401 - mae: 0.7510 - val_loss: 0.4844 - val_mae: 0.5181\n",
      "Epoch 17/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.9969 - mae: 0.7406 - val_loss: 0.4755 - val_mae: 0.5154\n",
      "Epoch 18/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.9740 - mae: 0.7311 - val_loss: 0.4759 - val_mae: 0.5150\n",
      "Epoch 19/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.9367 - mae: 0.7155 - val_loss: 0.4750 - val_mae: 0.5164\n",
      "Epoch 20/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.9162 - mae: 0.7065 - val_loss: 0.4721 - val_mae: 0.5143\n",
      "Epoch 21/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.8923 - mae: 0.6978 - val_loss: 0.4590 - val_mae: 0.5083\n",
      "Epoch 22/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.8851 - mae: 0.6916 - val_loss: 0.4821 - val_mae: 0.5240\n",
      "Epoch 23/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.8558 - mae: 0.6823 - val_loss: 0.4459 - val_mae: 0.5012\n",
      "Epoch 24/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.8303 - mae: 0.6706 - val_loss: 0.4518 - val_mae: 0.5054\n",
      "Epoch 25/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.8251 - mae: 0.6668 - val_loss: 0.4684 - val_mae: 0.5175\n",
      "Epoch 26/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.8056 - mae: 0.6604 - val_loss: 0.4713 - val_mae: 0.5181\n",
      "Epoch 27/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.8012 - mae: 0.6591 - val_loss: 0.4667 - val_mae: 0.5174\n",
      "Epoch 28/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.7944 - mae: 0.6552 - val_loss: 0.4515 - val_mae: 0.5110\n",
      "Epoch 29/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.7786 - mae: 0.6479 - val_loss: 0.4666 - val_mae: 0.5191\n",
      "Epoch 30/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.7647 - mae: 0.6436 - val_loss: 0.4529 - val_mae: 0.5125\n",
      "Epoch 31/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.7491 - mae: 0.6393 - val_loss: 0.4674 - val_mae: 0.5192\n",
      "Epoch 32/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.7525 - mae: 0.6378 - val_loss: 0.4601 - val_mae: 0.5178\n",
      "Epoch 33/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.7349 - mae: 0.6330 - val_loss: 0.4812 - val_mae: 0.5302\n",
      "Epoch 34/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.7452 - mae: 0.6347 - val_loss: 0.4782 - val_mae: 0.5298\n",
      "Epoch 35/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.7300 - mae: 0.6321 - val_loss: 0.4765 - val_mae: 0.5301\n",
      "Epoch 36/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.7260 - mae: 0.6261 - val_loss: 0.4587 - val_mae: 0.5194\n",
      "Epoch 37/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.7221 - mae: 0.6272 - val_loss: 0.4623 - val_mae: 0.5213\n",
      "Epoch 38/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.7140 - mae: 0.6219 - val_loss: 0.4725 - val_mae: 0.5281\n",
      "Epoch 39/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.6966 - mae: 0.6164 - val_loss: 0.4841 - val_mae: 0.5326\n",
      "Epoch 40/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.7017 - mae: 0.6183 - val_loss: 0.4722 - val_mae: 0.5280\n",
      "Epoch 41/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.6938 - mae: 0.6169 - val_loss: 0.4484 - val_mae: 0.5133\n",
      "Epoch 42/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.6968 - mae: 0.6161 - val_loss: 0.4367 - val_mae: 0.5058\n",
      "Epoch 43/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.6910 - mae: 0.6130 - val_loss: 0.4642 - val_mae: 0.5215\n",
      "Epoch 44/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.6810 - mae: 0.6094 - val_loss: 0.4458 - val_mae: 0.5113\n",
      "Epoch 45/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.6861 - mae: 0.6113 - val_loss: 0.4523 - val_mae: 0.5184\n",
      "Epoch 46/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.6760 - mae: 0.6078 - val_loss: 0.4489 - val_mae: 0.5138\n",
      "Epoch 47/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.6808 - mae: 0.6086 - val_loss: 0.4414 - val_mae: 0.5100\n",
      "Epoch 48/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.6623 - mae: 0.6025 - val_loss: 0.4306 - val_mae: 0.5043\n",
      "Epoch 49/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.6784 - mae: 0.6057 - val_loss: 0.4481 - val_mae: 0.5144\n",
      "Epoch 50/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.6577 - mae: 0.6017 - val_loss: 0.4424 - val_mae: 0.5114\n",
      "Epoch 51/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.6636 - mae: 0.5999 - val_loss: 0.4570 - val_mae: 0.5170\n",
      "Epoch 52/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.6513 - mae: 0.5992 - val_loss: 0.4531 - val_mae: 0.5167\n",
      "Epoch 53/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.6576 - mae: 0.5989 - val_loss: 0.4551 - val_mae: 0.5187\n",
      "Epoch 54/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.6504 - mae: 0.5963 - val_loss: 0.4373 - val_mae: 0.5090\n",
      "Epoch 55/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.6443 - mae: 0.5930 - val_loss: 0.4277 - val_mae: 0.5033\n",
      "Epoch 56/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.6466 - mae: 0.5932 - val_loss: 0.4166 - val_mae: 0.4950\n",
      "Epoch 57/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.6353 - mae: 0.5914 - val_loss: 0.4361 - val_mae: 0.5090\n",
      "Epoch 58/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.6402 - mae: 0.5914 - val_loss: 0.4372 - val_mae: 0.5088\n",
      "Epoch 59/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.6373 - mae: 0.5902 - val_loss: 0.4494 - val_mae: 0.5168\n",
      "Epoch 60/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.6267 - mae: 0.5880 - val_loss: 0.4431 - val_mae: 0.5127\n",
      "Epoch 61/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.6313 - mae: 0.5901 - val_loss: 0.4433 - val_mae: 0.5128\n",
      "Epoch 62/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.6338 - mae: 0.5879 - val_loss: 0.4477 - val_mae: 0.5161\n",
      "Epoch 63/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.6291 - mae: 0.5872 - val_loss: 0.4625 - val_mae: 0.5228\n",
      "Epoch 64/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.6152 - mae: 0.5831 - val_loss: 0.4425 - val_mae: 0.5142\n",
      "Epoch 65/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.6212 - mae: 0.5842 - val_loss: 0.4571 - val_mae: 0.5178\n",
      "Epoch 66/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.6306 - mae: 0.5872 - val_loss: 0.4478 - val_mae: 0.5137\n",
      "Epoch 67/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.6215 - mae: 0.5822 - val_loss: 0.4722 - val_mae: 0.5302\n",
      "Epoch 68/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.6132 - mae: 0.5782 - val_loss: 0.4401 - val_mae: 0.5112\n",
      "Epoch 69/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.6100 - mae: 0.5779 - val_loss: 0.4573 - val_mae: 0.5215\n",
      "Epoch 70/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.6146 - mae: 0.5786 - val_loss: 0.4463 - val_mae: 0.5176\n",
      "Epoch 71/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.6160 - mae: 0.5787 - val_loss: 0.4535 - val_mae: 0.5198\n",
      "Epoch 72/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.6162 - mae: 0.5785 - val_loss: 0.4345 - val_mae: 0.5096\n",
      "Epoch 73/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.6094 - mae: 0.5771 - val_loss: 0.4413 - val_mae: 0.5144\n",
      "Epoch 74/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.6006 - mae: 0.5728 - val_loss: 0.4727 - val_mae: 0.5321\n",
      "Epoch 75/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.6101 - mae: 0.5776 - val_loss: 0.4742 - val_mae: 0.5325\n",
      "Epoch 76/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.6074 - mae: 0.5739 - val_loss: 0.4491 - val_mae: 0.5189\n",
      "Epoch 77/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.6065 - mae: 0.5752 - val_loss: 0.4553 - val_mae: 0.5214\n",
      "Epoch 78/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.6010 - mae: 0.5736 - val_loss: 0.4485 - val_mae: 0.5170\n",
      "Epoch 79/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.6042 - mae: 0.5746 - val_loss: 0.4553 - val_mae: 0.5218\n",
      "Epoch 80/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.6007 - mae: 0.5710 - val_loss: 0.4550 - val_mae: 0.5202\n",
      "Epoch 81/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.6016 - mae: 0.5734 - val_loss: 0.4250 - val_mae: 0.5021\n",
      "Epoch 82/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.6045 - mae: 0.5729 - val_loss: 0.4470 - val_mae: 0.5173\n",
      "Epoch 83/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5954 - mae: 0.5723 - val_loss: 0.4641 - val_mae: 0.5261\n",
      "Epoch 84/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.6019 - mae: 0.5732 - val_loss: 0.4093 - val_mae: 0.4917\n",
      "Epoch 85/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5897 - mae: 0.5685 - val_loss: 0.4426 - val_mae: 0.5128\n",
      "Epoch 86/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5978 - mae: 0.5720 - val_loss: 0.4403 - val_mae: 0.5115\n",
      "Epoch 87/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5969 - mae: 0.5712 - val_loss: 0.4593 - val_mae: 0.5230\n",
      "Epoch 88/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5985 - mae: 0.5721 - val_loss: 0.4314 - val_mae: 0.5071\n",
      "Epoch 89/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5954 - mae: 0.5696 - val_loss: 0.4261 - val_mae: 0.5046\n",
      "Epoch 90/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5916 - mae: 0.5698 - val_loss: 0.4405 - val_mae: 0.5120\n",
      "Epoch 91/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5949 - mae: 0.5711 - val_loss: 0.4593 - val_mae: 0.5224\n",
      "Epoch 92/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5956 - mae: 0.5700 - val_loss: 0.4297 - val_mae: 0.5061\n",
      "Epoch 93/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5932 - mae: 0.5695 - val_loss: 0.4429 - val_mae: 0.5138\n",
      "Epoch 94/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5797 - mae: 0.5646 - val_loss: 0.4380 - val_mae: 0.5101\n",
      "Epoch 95/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5921 - mae: 0.5681 - val_loss: 0.4387 - val_mae: 0.5094\n",
      "Epoch 96/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5767 - mae: 0.5621 - val_loss: 0.4248 - val_mae: 0.5029\n",
      "Epoch 97/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5819 - mae: 0.5644 - val_loss: 0.4355 - val_mae: 0.5109\n",
      "Epoch 98/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5782 - mae: 0.5641 - val_loss: 0.4301 - val_mae: 0.5055\n",
      "Epoch 99/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5863 - mae: 0.5657 - val_loss: 0.4552 - val_mae: 0.5207\n",
      "Epoch 100/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5896 - mae: 0.5652 - val_loss: 0.4541 - val_mae: 0.5183\n",
      "Epoch 101/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5785 - mae: 0.5613 - val_loss: 0.4181 - val_mae: 0.4968\n",
      "Epoch 102/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5770 - mae: 0.5638 - val_loss: 0.4331 - val_mae: 0.5093\n",
      "Epoch 103/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5814 - mae: 0.5638 - val_loss: 0.4520 - val_mae: 0.5164\n",
      "Epoch 104/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5768 - mae: 0.5604 - val_loss: 0.4322 - val_mae: 0.5055\n",
      "Epoch 105/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5731 - mae: 0.5609 - val_loss: 0.4404 - val_mae: 0.5113\n",
      "Epoch 106/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5699 - mae: 0.5595 - val_loss: 0.4548 - val_mae: 0.5175\n",
      "Epoch 107/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5777 - mae: 0.5631 - val_loss: 0.4223 - val_mae: 0.4980\n",
      "Epoch 108/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5660 - mae: 0.5577 - val_loss: 0.4368 - val_mae: 0.5084\n",
      "Epoch 109/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5939 - mae: 0.5664 - val_loss: 0.4578 - val_mae: 0.5227\n",
      "Epoch 110/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5725 - mae: 0.5599 - val_loss: 0.4366 - val_mae: 0.5096\n",
      "Epoch 111/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5734 - mae: 0.5587 - val_loss: 0.4354 - val_mae: 0.5072\n",
      "Epoch 112/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5805 - mae: 0.5619 - val_loss: 0.4496 - val_mae: 0.5200\n",
      "Epoch 113/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5763 - mae: 0.5621 - val_loss: 0.4235 - val_mae: 0.5004\n",
      "Epoch 114/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5750 - mae: 0.5614 - val_loss: 0.4344 - val_mae: 0.5084\n",
      "Epoch 115/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5752 - mae: 0.5604 - val_loss: 0.4573 - val_mae: 0.5202\n",
      "Epoch 116/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5726 - mae: 0.5597 - val_loss: 0.4069 - val_mae: 0.4903\n",
      "Epoch 117/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5720 - mae: 0.5596 - val_loss: 0.4390 - val_mae: 0.5094\n",
      "Epoch 118/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5697 - mae: 0.5569 - val_loss: 0.4313 - val_mae: 0.5014\n",
      "Epoch 119/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5706 - mae: 0.5582 - val_loss: 0.4266 - val_mae: 0.5021\n",
      "Epoch 120/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5752 - mae: 0.5619 - val_loss: 0.4207 - val_mae: 0.4982\n",
      "Epoch 121/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5725 - mae: 0.5596 - val_loss: 0.4042 - val_mae: 0.4902\n",
      "Epoch 122/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5775 - mae: 0.5595 - val_loss: 0.4393 - val_mae: 0.5100\n",
      "Epoch 123/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5832 - mae: 0.5616 - val_loss: 0.4267 - val_mae: 0.5041\n",
      "Epoch 124/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5740 - mae: 0.5637 - val_loss: 0.4037 - val_mae: 0.4886\n",
      "Epoch 125/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5789 - mae: 0.5610 - val_loss: 0.4206 - val_mae: 0.5001\n",
      "Epoch 126/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5692 - mae: 0.5586 - val_loss: 0.4354 - val_mae: 0.5094\n",
      "Epoch 127/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5678 - mae: 0.5579 - val_loss: 0.4206 - val_mae: 0.5002\n",
      "Epoch 128/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5571 - mae: 0.5528 - val_loss: 0.4016 - val_mae: 0.4875\n",
      "Epoch 129/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5692 - mae: 0.5591 - val_loss: 0.4304 - val_mae: 0.5063\n",
      "Epoch 130/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5816 - mae: 0.5648 - val_loss: 0.3851 - val_mae: 0.4759\n",
      "Epoch 131/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5640 - mae: 0.5565 - val_loss: 0.4076 - val_mae: 0.4916\n",
      "Epoch 132/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5741 - mae: 0.5584 - val_loss: 0.4296 - val_mae: 0.5025\n",
      "Epoch 133/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5624 - mae: 0.5555 - val_loss: 0.4440 - val_mae: 0.5123\n",
      "Epoch 134/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5692 - mae: 0.5578 - val_loss: 0.4521 - val_mae: 0.5173\n",
      "Epoch 135/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5560 - mae: 0.5537 - val_loss: 0.4399 - val_mae: 0.5104\n",
      "Epoch 136/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5691 - mae: 0.5590 - val_loss: 0.4089 - val_mae: 0.4943\n",
      "Epoch 137/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5693 - mae: 0.5582 - val_loss: 0.4226 - val_mae: 0.5011\n",
      "Epoch 138/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5750 - mae: 0.5600 - val_loss: 0.4496 - val_mae: 0.5150\n",
      "Epoch 139/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5621 - mae: 0.5549 - val_loss: 0.4331 - val_mae: 0.5061\n",
      "Epoch 140/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5561 - mae: 0.5537 - val_loss: 0.4147 - val_mae: 0.4981\n",
      "Epoch 141/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5668 - mae: 0.5566 - val_loss: 0.4051 - val_mae: 0.4896\n",
      "Epoch 142/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5600 - mae: 0.5564 - val_loss: 0.4137 - val_mae: 0.4948\n",
      "Epoch 143/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5730 - mae: 0.5590 - val_loss: 0.4349 - val_mae: 0.5091\n",
      "Epoch 144/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5687 - mae: 0.5567 - val_loss: 0.4448 - val_mae: 0.5109\n",
      "Epoch 145/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5581 - mae: 0.5540 - val_loss: 0.4172 - val_mae: 0.4950\n",
      "Epoch 146/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5674 - mae: 0.5564 - val_loss: 0.3987 - val_mae: 0.4870\n",
      "Epoch 147/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5596 - mae: 0.5548 - val_loss: 0.4122 - val_mae: 0.4939\n",
      "Epoch 148/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5678 - mae: 0.5559 - val_loss: 0.4830 - val_mae: 0.5333\n",
      "Epoch 149/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5610 - mae: 0.5536 - val_loss: 0.4021 - val_mae: 0.4885\n",
      "Epoch 150/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5627 - mae: 0.5526 - val_loss: 0.4031 - val_mae: 0.4895\n",
      "Epoch 151/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5638 - mae: 0.5553 - val_loss: 0.4277 - val_mae: 0.5029\n",
      "Epoch 152/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5694 - mae: 0.5563 - val_loss: 0.4147 - val_mae: 0.4957\n",
      "Epoch 153/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5694 - mae: 0.5578 - val_loss: 0.4042 - val_mae: 0.4886\n",
      "Epoch 154/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5568 - mae: 0.5528 - val_loss: 0.3888 - val_mae: 0.4801\n",
      "Epoch 155/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5501 - mae: 0.5504 - val_loss: 0.4175 - val_mae: 0.4979\n",
      "Epoch 156/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5536 - mae: 0.5526 - val_loss: 0.4233 - val_mae: 0.5006\n",
      "Epoch 157/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5634 - mae: 0.5539 - val_loss: 0.4299 - val_mae: 0.5056\n",
      "Epoch 158/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5608 - mae: 0.5545 - val_loss: 0.3968 - val_mae: 0.4818\n",
      "Epoch 159/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5663 - mae: 0.5558 - val_loss: 0.4067 - val_mae: 0.4926\n",
      "Epoch 160/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5638 - mae: 0.5567 - val_loss: 0.4287 - val_mae: 0.5054\n",
      "Epoch 161/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5534 - mae: 0.5515 - val_loss: 0.4076 - val_mae: 0.4930\n",
      "Epoch 162/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5604 - mae: 0.5557 - val_loss: 0.3998 - val_mae: 0.4871\n",
      "Epoch 163/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5610 - mae: 0.5547 - val_loss: 0.4366 - val_mae: 0.5090\n",
      "Epoch 164/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5696 - mae: 0.5577 - val_loss: 0.4304 - val_mae: 0.5042\n",
      "Epoch 165/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5578 - mae: 0.5527 - val_loss: 0.4005 - val_mae: 0.4898\n",
      "Epoch 166/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5523 - mae: 0.5498 - val_loss: 0.3943 - val_mae: 0.4840\n",
      "Epoch 167/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5585 - mae: 0.5528 - val_loss: 0.4340 - val_mae: 0.5073\n",
      "Epoch 168/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5617 - mae: 0.5537 - val_loss: 0.4123 - val_mae: 0.4938\n",
      "Epoch 169/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5650 - mae: 0.5560 - val_loss: 0.4151 - val_mae: 0.4944\n",
      "Epoch 170/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5563 - mae: 0.5527 - val_loss: 0.4131 - val_mae: 0.4971\n",
      "Epoch 171/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5575 - mae: 0.5514 - val_loss: 0.3882 - val_mae: 0.4788\n",
      "Epoch 172/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5613 - mae: 0.5541 - val_loss: 0.4328 - val_mae: 0.5046\n",
      "Epoch 173/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5639 - mae: 0.5549 - val_loss: 0.4120 - val_mae: 0.4934\n",
      "Epoch 174/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5494 - mae: 0.5503 - val_loss: 0.4064 - val_mae: 0.4930\n",
      "Epoch 175/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5584 - mae: 0.5530 - val_loss: 0.4379 - val_mae: 0.5089\n",
      "Epoch 176/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5575 - mae: 0.5525 - val_loss: 0.4295 - val_mae: 0.5024\n",
      "Epoch 177/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5527 - mae: 0.5512 - val_loss: 0.4089 - val_mae: 0.4921\n",
      "Epoch 178/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5587 - mae: 0.5540 - val_loss: 0.4064 - val_mae: 0.4931\n",
      "Epoch 179/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5574 - mae: 0.5522 - val_loss: 0.3910 - val_mae: 0.4809\n",
      "Epoch 180/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5585 - mae: 0.5538 - val_loss: 0.4202 - val_mae: 0.4991\n",
      "Epoch 181/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5563 - mae: 0.5520 - val_loss: 0.4116 - val_mae: 0.4928\n",
      "Epoch 182/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5586 - mae: 0.5502 - val_loss: 0.4315 - val_mae: 0.5059\n",
      "Epoch 183/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5616 - mae: 0.5534 - val_loss: 0.4186 - val_mae: 0.4975\n",
      "Epoch 184/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5457 - mae: 0.5477 - val_loss: 0.4391 - val_mae: 0.5106\n",
      "Epoch 185/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5609 - mae: 0.5527 - val_loss: 0.4071 - val_mae: 0.4927\n",
      "Epoch 186/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5487 - mae: 0.5484 - val_loss: 0.4304 - val_mae: 0.5047\n",
      "Epoch 187/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5557 - mae: 0.5519 - val_loss: 0.4275 - val_mae: 0.5015\n",
      "Epoch 188/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5512 - mae: 0.5498 - val_loss: 0.4182 - val_mae: 0.4981\n",
      "Epoch 189/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5524 - mae: 0.5510 - val_loss: 0.4275 - val_mae: 0.5024\n",
      "Epoch 190/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5547 - mae: 0.5497 - val_loss: 0.3988 - val_mae: 0.4843\n",
      "Epoch 191/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5519 - mae: 0.5475 - val_loss: 0.4127 - val_mae: 0.4920\n",
      "Epoch 192/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5486 - mae: 0.5477 - val_loss: 0.4438 - val_mae: 0.5152\n",
      "Epoch 193/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5563 - mae: 0.5517 - val_loss: 0.4535 - val_mae: 0.5161\n",
      "Epoch 194/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5624 - mae: 0.5532 - val_loss: 0.4132 - val_mae: 0.4926\n",
      "Epoch 195/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5527 - mae: 0.5493 - val_loss: 0.4169 - val_mae: 0.4972\n",
      "Epoch 196/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5488 - mae: 0.5479 - val_loss: 0.4378 - val_mae: 0.5082\n",
      "Epoch 197/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5528 - mae: 0.5489 - val_loss: 0.4297 - val_mae: 0.5038\n",
      "Epoch 198/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5543 - mae: 0.5508 - val_loss: 0.4527 - val_mae: 0.5179\n",
      "Epoch 199/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5502 - mae: 0.5489 - val_loss: 0.4011 - val_mae: 0.4870\n",
      "Epoch 200/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5568 - mae: 0.5517 - val_loss: 0.4077 - val_mae: 0.4905\n",
      "Epoch 201/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5560 - mae: 0.5504 - val_loss: 0.4438 - val_mae: 0.5109\n",
      "Epoch 202/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5530 - mae: 0.5499 - val_loss: 0.3980 - val_mae: 0.4827\n",
      "Epoch 203/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5503 - mae: 0.5486 - val_loss: 0.4369 - val_mae: 0.5061\n",
      "Epoch 204/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5508 - mae: 0.5501 - val_loss: 0.4465 - val_mae: 0.5131\n",
      "Epoch 205/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5580 - mae: 0.5516 - val_loss: 0.4040 - val_mae: 0.4908\n",
      "Epoch 206/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5586 - mae: 0.5519 - val_loss: 0.4129 - val_mae: 0.4931\n",
      "Epoch 207/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5520 - mae: 0.5490 - val_loss: 0.4270 - val_mae: 0.5009\n",
      "Epoch 208/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5493 - mae: 0.5487 - val_loss: 0.3992 - val_mae: 0.4851\n",
      "Epoch 209/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5574 - mae: 0.5514 - val_loss: 0.4041 - val_mae: 0.4894\n",
      "Epoch 210/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5528 - mae: 0.5489 - val_loss: 0.4004 - val_mae: 0.4818\n",
      "Epoch 211/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5510 - mae: 0.5496 - val_loss: 0.4374 - val_mae: 0.5088\n",
      "Epoch 212/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5538 - mae: 0.5505 - val_loss: 0.4034 - val_mae: 0.4879\n",
      "Epoch 213/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5569 - mae: 0.5518 - val_loss: 0.4313 - val_mae: 0.5032\n",
      "Epoch 214/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5547 - mae: 0.5499 - val_loss: 0.4387 - val_mae: 0.5084\n",
      "Epoch 215/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5506 - mae: 0.5504 - val_loss: 0.4088 - val_mae: 0.4917\n",
      "Epoch 216/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5503 - mae: 0.5496 - val_loss: 0.4135 - val_mae: 0.4950\n",
      "Epoch 217/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5525 - mae: 0.5489 - val_loss: 0.4234 - val_mae: 0.5003\n",
      "Epoch 218/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5534 - mae: 0.5504 - val_loss: 0.4215 - val_mae: 0.4970\n",
      "Epoch 219/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5538 - mae: 0.5493 - val_loss: 0.3999 - val_mae: 0.4851\n",
      "Epoch 220/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5514 - mae: 0.5481 - val_loss: 0.4005 - val_mae: 0.4856\n",
      "Epoch 221/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5535 - mae: 0.5503 - val_loss: 0.4674 - val_mae: 0.5255\n",
      "Epoch 222/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5507 - mae: 0.5492 - val_loss: 0.4090 - val_mae: 0.4904\n",
      "Epoch 223/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5565 - mae: 0.5515 - val_loss: 0.4282 - val_mae: 0.5025\n",
      "Epoch 224/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5493 - mae: 0.5461 - val_loss: 0.4216 - val_mae: 0.4990\n",
      "Epoch 225/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5558 - mae: 0.5497 - val_loss: 0.4442 - val_mae: 0.5111\n",
      "Epoch 226/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5546 - mae: 0.5499 - val_loss: 0.4264 - val_mae: 0.4988\n",
      "Epoch 227/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5567 - mae: 0.5502 - val_loss: 0.4175 - val_mae: 0.4965\n",
      "Epoch 228/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5476 - mae: 0.5477 - val_loss: 0.4254 - val_mae: 0.5002\n",
      "Epoch 229/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5482 - mae: 0.5469 - val_loss: 0.4366 - val_mae: 0.5061\n",
      "Epoch 230/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5469 - mae: 0.5468 - val_loss: 0.4227 - val_mae: 0.4992\n",
      "Epoch 231/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5546 - mae: 0.5500 - val_loss: 0.4272 - val_mae: 0.5022\n",
      "Epoch 232/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5377 - mae: 0.5434 - val_loss: 0.4115 - val_mae: 0.4941\n",
      "Epoch 233/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5481 - mae: 0.5468 - val_loss: 0.4180 - val_mae: 0.4959\n",
      "Epoch 234/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5331 - mae: 0.5419 - val_loss: 0.4356 - val_mae: 0.5099\n",
      "Epoch 235/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5449 - mae: 0.5469 - val_loss: 0.4273 - val_mae: 0.5027\n",
      "Epoch 236/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5497 - mae: 0.5477 - val_loss: 0.4200 - val_mae: 0.4979\n",
      "Epoch 237/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5474 - mae: 0.5483 - val_loss: 0.4511 - val_mae: 0.5155\n",
      "Epoch 238/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5471 - mae: 0.5481 - val_loss: 0.4322 - val_mae: 0.5070\n",
      "Epoch 239/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5446 - mae: 0.5464 - val_loss: 0.4154 - val_mae: 0.4965\n",
      "Epoch 240/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5527 - mae: 0.5492 - val_loss: 0.4569 - val_mae: 0.5177\n",
      "Epoch 241/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5378 - mae: 0.5429 - val_loss: 0.4197 - val_mae: 0.4966\n",
      "Epoch 242/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5526 - mae: 0.5501 - val_loss: 0.4239 - val_mae: 0.4994\n",
      "Epoch 243/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5477 - mae: 0.5482 - val_loss: 0.4212 - val_mae: 0.5003\n",
      "Epoch 244/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5514 - mae: 0.5484 - val_loss: 0.4511 - val_mae: 0.5144\n",
      "Epoch 245/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.5501 - mae: 0.5466 - val_loss: 0.4025 - val_mae: 0.4876\n",
      "Epoch 246/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.5525 - mae: 0.5473 - val_loss: 0.3824 - val_mae: 0.4747\n",
      "Epoch 247/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5441 - mae: 0.5448 - val_loss: 0.3893 - val_mae: 0.4799\n",
      "Epoch 248/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5527 - mae: 0.5477 - val_loss: 0.4025 - val_mae: 0.4883\n",
      "Epoch 249/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5580 - mae: 0.5483 - val_loss: 0.4273 - val_mae: 0.5025\n",
      "Epoch 250/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5438 - mae: 0.5482 - val_loss: 0.4066 - val_mae: 0.4923\n",
      "Epoch 251/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5523 - mae: 0.5486 - val_loss: 0.4215 - val_mae: 0.5002\n",
      "Epoch 252/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5434 - mae: 0.5463 - val_loss: 0.4105 - val_mae: 0.4927\n",
      "Epoch 253/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.5508 - mae: 0.5497 - val_loss: 0.3901 - val_mae: 0.4796\n",
      "Epoch 254/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5452 - mae: 0.5475 - val_loss: 0.4189 - val_mae: 0.4953\n",
      "Epoch 255/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5427 - mae: 0.5445 - val_loss: 0.4142 - val_mae: 0.4939\n",
      "Epoch 256/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5482 - mae: 0.5496 - val_loss: 0.4178 - val_mae: 0.4972\n",
      "Epoch 257/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5451 - mae: 0.5457 - val_loss: 0.4392 - val_mae: 0.5097\n",
      "Epoch 258/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5556 - mae: 0.5517 - val_loss: 0.4456 - val_mae: 0.5105\n",
      "Epoch 259/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5505 - mae: 0.5470 - val_loss: 0.4481 - val_mae: 0.5151\n",
      "Epoch 260/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5514 - mae: 0.5482 - val_loss: 0.4526 - val_mae: 0.5158\n",
      "Epoch 261/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5474 - mae: 0.5479 - val_loss: 0.4026 - val_mae: 0.4877\n",
      "Epoch 262/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5440 - mae: 0.5459 - val_loss: 0.4632 - val_mae: 0.5220\n",
      "Epoch 263/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5535 - mae: 0.5485 - val_loss: 0.4223 - val_mae: 0.4979\n",
      "Epoch 264/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.5430 - mae: 0.5452 - val_loss: 0.4120 - val_mae: 0.4937\n",
      "Epoch 265/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5567 - mae: 0.5488 - val_loss: 0.4346 - val_mae: 0.5062\n",
      "Epoch 266/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5536 - mae: 0.5511 - val_loss: 0.4112 - val_mae: 0.4934\n",
      "Epoch 267/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5426 - mae: 0.5459 - val_loss: 0.4199 - val_mae: 0.4983\n",
      "Epoch 268/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.5500 - mae: 0.5478 - val_loss: 0.4345 - val_mae: 0.5046\n",
      "Epoch 269/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5450 - mae: 0.5470 - val_loss: 0.4238 - val_mae: 0.5005\n",
      "Epoch 270/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5497 - mae: 0.5501 - val_loss: 0.4386 - val_mae: 0.5097\n",
      "Epoch 271/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5449 - mae: 0.5462 - val_loss: 0.4505 - val_mae: 0.5148\n",
      "Epoch 272/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5508 - mae: 0.5480 - val_loss: 0.4599 - val_mae: 0.5207\n",
      "Epoch 273/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5437 - mae: 0.5441 - val_loss: 0.4103 - val_mae: 0.4927\n",
      "Epoch 274/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5438 - mae: 0.5467 - val_loss: 0.4234 - val_mae: 0.5002\n",
      "Epoch 275/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5445 - mae: 0.5466 - val_loss: 0.4223 - val_mae: 0.4985\n",
      "Epoch 276/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5404 - mae: 0.5449 - val_loss: 0.4663 - val_mae: 0.5231\n",
      "Epoch 277/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5477 - mae: 0.5494 - val_loss: 0.4115 - val_mae: 0.4915\n",
      "Epoch 278/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5552 - mae: 0.5491 - val_loss: 0.4521 - val_mae: 0.5155\n",
      "Epoch 279/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5456 - mae: 0.5453 - val_loss: 0.4327 - val_mae: 0.5056\n",
      "Epoch 280/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5553 - mae: 0.5512 - val_loss: 0.4192 - val_mae: 0.4966\n",
      "Epoch 281/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5402 - mae: 0.5446 - val_loss: 0.4190 - val_mae: 0.4981\n",
      "Epoch 282/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5463 - mae: 0.5443 - val_loss: 0.4062 - val_mae: 0.4908\n",
      "Epoch 283/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5460 - mae: 0.5468 - val_loss: 0.4170 - val_mae: 0.4951\n",
      "Epoch 284/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5482 - mae: 0.5478 - val_loss: 0.4293 - val_mae: 0.5052\n",
      "Epoch 285/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5392 - mae: 0.5456 - val_loss: 0.4551 - val_mae: 0.5192\n",
      "Epoch 286/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5390 - mae: 0.5436 - val_loss: 0.4125 - val_mae: 0.4916\n",
      "Epoch 287/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5556 - mae: 0.5470 - val_loss: 0.4008 - val_mae: 0.4867\n",
      "Epoch 288/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5455 - mae: 0.5452 - val_loss: 0.4305 - val_mae: 0.5028\n",
      "Epoch 289/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5483 - mae: 0.5470 - val_loss: 0.4511 - val_mae: 0.5168\n",
      "Epoch 290/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5479 - mae: 0.5476 - val_loss: 0.4205 - val_mae: 0.4992\n",
      "Epoch 291/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5447 - mae: 0.5454 - val_loss: 0.4500 - val_mae: 0.5137\n",
      "Epoch 292/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5395 - mae: 0.5428 - val_loss: 0.4376 - val_mae: 0.5070\n",
      "Epoch 293/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5481 - mae: 0.5477 - val_loss: 0.4308 - val_mae: 0.5039\n",
      "Epoch 294/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5419 - mae: 0.5457 - val_loss: 0.4514 - val_mae: 0.5176\n",
      "Epoch 295/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5444 - mae: 0.5468 - val_loss: 0.3947 - val_mae: 0.4826\n",
      "Epoch 296/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5512 - mae: 0.5488 - val_loss: 0.4305 - val_mae: 0.5046\n",
      "Epoch 297/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5373 - mae: 0.5431 - val_loss: 0.4283 - val_mae: 0.5030\n",
      "Epoch 298/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5415 - mae: 0.5442 - val_loss: 0.4009 - val_mae: 0.4877\n",
      "Epoch 299/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5390 - mae: 0.5435 - val_loss: 0.4581 - val_mae: 0.5185\n",
      "Epoch 300/300\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5363 - mae: 0.5422 - val_loss: 0.4075 - val_mae: 0.4902\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_split=0.2,  # Use 20% of training data for validation\n",
    "    epochs=300,  # Number of epochs (adjust as needed)\n",
    "    batch_size=32,  # Batch size\n",
    "    verbose=1 , # Display training progress\n",
    "    callbacks=[tensorboard_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fa1b101be39f5daa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T20:49:06.425908500Z",
     "start_time": "2024-12-26T20:49:04.178332Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2016/2016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 490us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1c4c574add488773",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T20:49:08.725723500Z",
     "start_time": "2024-12-26T20:49:08.722413600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions_df = pd.DataFrame(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "71b333248aa7be59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T20:49:10.419610700Z",
     "start_time": "2024-12-26T20:49:10.410196900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "column_from_df1 = df_test[\"Unnamed: 0\"]\n",
    "column_from_df2 = predictions_df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "207d7ab39242cd84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T20:49:11.324701400Z",
     "start_time": "2024-12-26T20:49:11.315733500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions_df = pd.concat([column_from_df1, column_from_df2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3363d337b3d8fec3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T20:49:12.037924900Z",
     "start_time": "2024-12-26T20:49:12.014428900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions_df.columns = ['id', 'target_feature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2cf96c0a943975ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T20:49:13.574466100Z",
     "start_time": "2024-12-26T20:49:13.562246500Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target_feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>8.108196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017</td>\n",
       "      <td>8.421997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018</td>\n",
       "      <td>8.570551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019</td>\n",
       "      <td>8.183589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>7.354485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64507</th>\n",
       "      <td>193531</td>\n",
       "      <td>5.631281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64508</th>\n",
       "      <td>193532</td>\n",
       "      <td>5.263395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64509</th>\n",
       "      <td>193533</td>\n",
       "      <td>5.349839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64510</th>\n",
       "      <td>193534</td>\n",
       "      <td>5.533175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64511</th>\n",
       "      <td>193535</td>\n",
       "      <td>5.563107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64512 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  target_feature\n",
       "0        2016        8.108196\n",
       "1        2017        8.421997\n",
       "2        2018        8.570551\n",
       "3        2019        8.183589\n",
       "4        2020        7.354485\n",
       "...       ...             ...\n",
       "64507  193531        5.631281\n",
       "64508  193532        5.263395\n",
       "64509  193533        5.349839\n",
       "64510  193534        5.533175\n",
       "64511  193535        5.563107\n",
       "\n",
       "[64512 rows x 2 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dde2bda3b8c7fbcb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T20:49:14.518681700Z",
     "start_time": "2024-12-26T20:49:14.515898800Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                  int64\n",
      "target_feature    float32\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(predictions_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b5905211f51fbdcb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T20:49:15.474591100Z",
     "start_time": "2024-12-26T20:49:15.446465100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(\"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9c328edf52ee3b1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T20:49:16.052757800Z",
     "start_time": "2024-12-26T20:49:16.041912300Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target_feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64507</th>\n",
       "      <td>193531</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64508</th>\n",
       "      <td>193532</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64509</th>\n",
       "      <td>193533</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64510</th>\n",
       "      <td>193534</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64511</th>\n",
       "      <td>193535</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64512 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  target_feature\n",
       "0        2016             5.0\n",
       "1        2017             5.0\n",
       "2        2018             5.0\n",
       "3        2019             5.0\n",
       "4        2020             5.0\n",
       "...       ...             ...\n",
       "64507  193531             5.0\n",
       "64508  193532             5.0\n",
       "64509  193533             5.0\n",
       "64510  193534             5.0\n",
       "64511  193535             5.0\n",
       "\n",
       "[64512 rows x 2 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a2f883791e565ab2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T20:49:17.438766300Z",
     "start_time": "2024-12-26T20:49:17.435834200Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                  int64\n",
      "target_feature    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(sample_submission.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1377d54064648d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T20:49:28.165893Z",
     "start_time": "2024-12-26T20:49:28.055070700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save submission as CSV file\n",
    "predictions_df.to_csv('D:\\\\Python\\\\Predict the wind speed at a wind turbine\\\\submissions\\\\oleg_bissing_submission_5.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
