{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T18:09:42.603175600Z",
     "start_time": "2024-12-26T18:09:39.544454900Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input, BatchNormalization\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "460cc4f5342e76a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T18:24:00.174505400Z",
     "start_time": "2024-12-26T18:23:59.208167400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train_data_FULL.csv')\n",
    "df_test = pd.read_csv('test_data_FULL.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "200f29bc64cd27dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T18:25:25.210178500Z",
     "start_time": "2024-12-26T18:25:25.207673200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = df_train.iloc[:, :-1].values  # All columns except the last as features\n",
    "y_train = df_train.iloc[:, -1].values   # Last column as target\n",
    "X_test = df_test.iloc[:, 1:].values   # All columns except the first as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2ecf4d8e4c5734a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T18:25:26.659625Z",
     "start_time": "2024-12-26T18:25:26.583157700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a977cfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a directory for TensorBoard logs\n",
    "tensorboard_callback = TensorBoard(log_dir='D:\\\\Python\\\\TBlogs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f20d2fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the EarlyStopping callback\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # Metric to monitor\n",
    "    patience=30,         # Number of epochs to wait without improvement\n",
    "    restore_best_weights=True  # Restore the weights of the best epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea3ea8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(learning_rate=0.001) # default is 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82b0488e16aa75ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T18:13:45.169520100Z",
     "start_time": "2024-12-26T18:13:45.034463500Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m6,528\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,897</span> (66.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m16,897\u001b[0m (66.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,897</span> (66.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m16,897\u001b[0m (66.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the FCNN model\n",
    "model = Sequential([\n",
    "    Input(shape=(X_train.shape[1],)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='linear')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
    "\n",
    "# Model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a67c14d44de616c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T20:42:25.043735900Z",
     "start_time": "2024-12-26T20:35:01.514150100Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - loss: 4.7649 - mae: 1.5620 - val_loss: 0.8635 - val_mae: 0.6756\n",
      "Epoch 2/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 1.5289 - mae: 0.9106 - val_loss: 0.6238 - val_mae: 0.5801\n",
      "Epoch 3/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 1.1252 - mae: 0.7764 - val_loss: 0.5356 - val_mae: 0.5415\n",
      "Epoch 4/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.9035 - mae: 0.6978 - val_loss: 0.5636 - val_mae: 0.5599\n",
      "Epoch 5/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.8314 - mae: 0.6661 - val_loss: 0.5699 - val_mae: 0.5835\n",
      "Epoch 6/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.7698 - mae: 0.6446 - val_loss: 0.6063 - val_mae: 0.6016\n",
      "Epoch 7/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 0.7561 - mae: 0.6403 - val_loss: 0.6206 - val_mae: 0.6164\n",
      "Epoch 8/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.7419 - mae: 0.6348 - val_loss: 0.6875 - val_mae: 0.6447\n",
      "Epoch 9/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.7205 - mae: 0.6285 - val_loss: 0.6511 - val_mae: 0.6301\n",
      "Epoch 10/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 0.7247 - mae: 0.6288 - val_loss: 0.6006 - val_mae: 0.6006\n",
      "Epoch 11/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.7039 - mae: 0.6207 - val_loss: 0.6477 - val_mae: 0.6256\n",
      "Epoch 12/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6881 - mae: 0.6141 - val_loss: 0.5096 - val_mae: 0.5576\n",
      "Epoch 13/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 0.6926 - mae: 0.6156 - val_loss: 0.5957 - val_mae: 0.6028\n",
      "Epoch 14/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 0.6738 - mae: 0.6067 - val_loss: 0.7164 - val_mae: 0.6594\n",
      "Epoch 15/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6754 - mae: 0.6088 - val_loss: 0.5410 - val_mae: 0.5807\n",
      "Epoch 16/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6820 - mae: 0.6054 - val_loss: 0.4824 - val_mae: 0.5469\n",
      "Epoch 17/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 0.6639 - mae: 0.6019 - val_loss: 0.5011 - val_mae: 0.5598\n",
      "Epoch 18/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 0.6604 - mae: 0.6035 - val_loss: 0.5730 - val_mae: 0.5921\n",
      "Epoch 19/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6523 - mae: 0.6004 - val_loss: 0.5370 - val_mae: 0.5766\n",
      "Epoch 20/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.6696 - mae: 0.6038 - val_loss: 0.5749 - val_mae: 0.5963\n",
      "Epoch 21/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6560 - mae: 0.5984 - val_loss: 0.5136 - val_mae: 0.5608\n",
      "Epoch 22/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6701 - mae: 0.6041 - val_loss: 0.5026 - val_mae: 0.5594\n",
      "Epoch 23/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6591 - mae: 0.5986 - val_loss: 0.4791 - val_mae: 0.5482\n",
      "Epoch 24/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6461 - mae: 0.5932 - val_loss: 0.4747 - val_mae: 0.5405\n",
      "Epoch 25/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6543 - mae: 0.5976 - val_loss: 0.5212 - val_mae: 0.5694\n",
      "Epoch 26/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6610 - mae: 0.5961 - val_loss: 0.5626 - val_mae: 0.5828\n",
      "Epoch 27/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6354 - mae: 0.5915 - val_loss: 0.5123 - val_mae: 0.5650\n",
      "Epoch 28/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6469 - mae: 0.5939 - val_loss: 0.5586 - val_mae: 0.5874\n",
      "Epoch 29/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6625 - mae: 0.5985 - val_loss: 0.5908 - val_mae: 0.6037\n",
      "Epoch 30/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6443 - mae: 0.5933 - val_loss: 0.4627 - val_mae: 0.5332\n",
      "Epoch 31/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6430 - mae: 0.5912 - val_loss: 0.4775 - val_mae: 0.5425\n",
      "Epoch 32/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6428 - mae: 0.5915 - val_loss: 0.4939 - val_mae: 0.5475\n",
      "Epoch 33/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6542 - mae: 0.5939 - val_loss: 0.6038 - val_mae: 0.6081\n",
      "Epoch 34/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6370 - mae: 0.5901 - val_loss: 0.5338 - val_mae: 0.5681\n",
      "Epoch 35/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6587 - mae: 0.5939 - val_loss: 0.4592 - val_mae: 0.5300\n",
      "Epoch 36/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6367 - mae: 0.5889 - val_loss: 0.5211 - val_mae: 0.5637\n",
      "Epoch 37/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6377 - mae: 0.5910 - val_loss: 0.5423 - val_mae: 0.5754\n",
      "Epoch 38/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6232 - mae: 0.5852 - val_loss: 0.4753 - val_mae: 0.5414\n",
      "Epoch 39/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6396 - mae: 0.5929 - val_loss: 0.4714 - val_mae: 0.5398\n",
      "Epoch 40/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6319 - mae: 0.5881 - val_loss: 0.4317 - val_mae: 0.5168\n",
      "Epoch 41/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6315 - mae: 0.5857 - val_loss: 0.4654 - val_mae: 0.5316\n",
      "Epoch 42/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6304 - mae: 0.5858 - val_loss: 0.4243 - val_mae: 0.5105\n",
      "Epoch 43/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6326 - mae: 0.5894 - val_loss: 0.4591 - val_mae: 0.5282\n",
      "Epoch 44/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6288 - mae: 0.5861 - val_loss: 0.5231 - val_mae: 0.5702\n",
      "Epoch 45/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6336 - mae: 0.5879 - val_loss: 0.5249 - val_mae: 0.5687\n",
      "Epoch 46/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6230 - mae: 0.5844 - val_loss: 0.4049 - val_mae: 0.5014\n",
      "Epoch 47/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6419 - mae: 0.5878 - val_loss: 0.4838 - val_mae: 0.5452\n",
      "Epoch 48/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6221 - mae: 0.5821 - val_loss: 0.4765 - val_mae: 0.5411\n",
      "Epoch 49/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6270 - mae: 0.5847 - val_loss: 0.5485 - val_mae: 0.5793\n",
      "Epoch 50/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6198 - mae: 0.5824 - val_loss: 0.4828 - val_mae: 0.5454\n",
      "Epoch 51/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6245 - mae: 0.5848 - val_loss: 0.4837 - val_mae: 0.5463\n",
      "Epoch 52/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6247 - mae: 0.5858 - val_loss: 0.3837 - val_mae: 0.4841\n",
      "Epoch 53/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6237 - mae: 0.5830 - val_loss: 0.4449 - val_mae: 0.5240\n",
      "Epoch 54/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6252 - mae: 0.5846 - val_loss: 0.5041 - val_mae: 0.5574\n",
      "Epoch 55/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6304 - mae: 0.5868 - val_loss: 0.5271 - val_mae: 0.5685\n",
      "Epoch 56/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6161 - mae: 0.5817 - val_loss: 0.4919 - val_mae: 0.5530\n",
      "Epoch 57/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6218 - mae: 0.5853 - val_loss: 0.5473 - val_mae: 0.5805\n",
      "Epoch 58/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6234 - mae: 0.5825 - val_loss: 0.4004 - val_mae: 0.4902\n",
      "Epoch 59/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6145 - mae: 0.5810 - val_loss: 0.5306 - val_mae: 0.5681\n",
      "Epoch 60/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6181 - mae: 0.5805 - val_loss: 0.5465 - val_mae: 0.5769\n",
      "Epoch 61/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6179 - mae: 0.5821 - val_loss: 0.4565 - val_mae: 0.5272\n",
      "Epoch 62/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6108 - mae: 0.5798 - val_loss: 0.3692 - val_mae: 0.4754\n",
      "Epoch 63/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6331 - mae: 0.5858 - val_loss: 0.3882 - val_mae: 0.4882\n",
      "Epoch 64/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6161 - mae: 0.5800 - val_loss: 0.4149 - val_mae: 0.5092\n",
      "Epoch 65/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6205 - mae: 0.5803 - val_loss: 0.3666 - val_mae: 0.4726\n",
      "Epoch 66/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6086 - mae: 0.5805 - val_loss: 0.4219 - val_mae: 0.5126\n",
      "Epoch 67/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6104 - mae: 0.5803 - val_loss: 0.4548 - val_mae: 0.5258\n",
      "Epoch 68/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6196 - mae: 0.5816 - val_loss: 0.4877 - val_mae: 0.5480\n",
      "Epoch 69/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6378 - mae: 0.5867 - val_loss: 0.4945 - val_mae: 0.5475\n",
      "Epoch 70/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6100 - mae: 0.5776 - val_loss: 0.4871 - val_mae: 0.5439\n",
      "Epoch 71/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6202 - mae: 0.5804 - val_loss: 0.4372 - val_mae: 0.5163\n",
      "Epoch 72/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6163 - mae: 0.5795 - val_loss: 0.4643 - val_mae: 0.5349\n",
      "Epoch 73/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6074 - mae: 0.5779 - val_loss: 0.4534 - val_mae: 0.5272\n",
      "Epoch 74/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6169 - mae: 0.5808 - val_loss: 0.4431 - val_mae: 0.5197\n",
      "Epoch 75/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6131 - mae: 0.5801 - val_loss: 0.4228 - val_mae: 0.5096\n",
      "Epoch 76/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6171 - mae: 0.5784 - val_loss: 0.4159 - val_mae: 0.5046\n",
      "Epoch 77/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6285 - mae: 0.5815 - val_loss: 0.5479 - val_mae: 0.5800\n",
      "Epoch 78/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6129 - mae: 0.5775 - val_loss: 0.4717 - val_mae: 0.5379\n",
      "Epoch 79/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6133 - mae: 0.5780 - val_loss: 0.5290 - val_mae: 0.5665\n",
      "Epoch 80/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6108 - mae: 0.5781 - val_loss: 0.4635 - val_mae: 0.5347\n",
      "Epoch 81/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6281 - mae: 0.5838 - val_loss: 0.4293 - val_mae: 0.5105\n",
      "Epoch 82/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6299 - mae: 0.5851 - val_loss: 0.4672 - val_mae: 0.5362\n",
      "Epoch 83/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6204 - mae: 0.5808 - val_loss: 0.4052 - val_mae: 0.4966\n",
      "Epoch 84/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6129 - mae: 0.5790 - val_loss: 0.5001 - val_mae: 0.5502\n",
      "Epoch 85/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6198 - mae: 0.5797 - val_loss: 0.4638 - val_mae: 0.5344\n",
      "Epoch 86/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6098 - mae: 0.5782 - val_loss: 0.3680 - val_mae: 0.4730\n",
      "Epoch 87/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6143 - mae: 0.5810 - val_loss: 0.4211 - val_mae: 0.5086\n",
      "Epoch 88/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6132 - mae: 0.5761 - val_loss: 0.4474 - val_mae: 0.5250\n",
      "Epoch 89/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6187 - mae: 0.5806 - val_loss: 0.3745 - val_mae: 0.4803\n",
      "Epoch 90/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6104 - mae: 0.5795 - val_loss: 0.4673 - val_mae: 0.5337\n",
      "Epoch 91/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6160 - mae: 0.5779 - val_loss: 0.4632 - val_mae: 0.5344\n",
      "Epoch 92/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6056 - mae: 0.5785 - val_loss: 0.5241 - val_mae: 0.5609\n",
      "Epoch 93/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6207 - mae: 0.5810 - val_loss: 0.4987 - val_mae: 0.5500\n",
      "Epoch 94/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6061 - mae: 0.5787 - val_loss: 0.4526 - val_mae: 0.5266\n",
      "Epoch 95/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6115 - mae: 0.5766 - val_loss: 0.4571 - val_mae: 0.5269\n",
      "Epoch 96/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6177 - mae: 0.5797 - val_loss: 0.4076 - val_mae: 0.5010\n",
      "Epoch 97/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6009 - mae: 0.5745 - val_loss: 0.4654 - val_mae: 0.5336\n",
      "Epoch 98/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6050 - mae: 0.5766 - val_loss: 0.4050 - val_mae: 0.5021\n",
      "Epoch 99/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6046 - mae: 0.5724 - val_loss: 0.4279 - val_mae: 0.5094\n",
      "Epoch 100/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6042 - mae: 0.5744 - val_loss: 0.5133 - val_mae: 0.5586\n",
      "Epoch 101/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6118 - mae: 0.5773 - val_loss: 0.3384 - val_mae: 0.4492\n",
      "Epoch 102/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6062 - mae: 0.5762 - val_loss: 0.4184 - val_mae: 0.5091\n",
      "Epoch 103/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6079 - mae: 0.5762 - val_loss: 0.4082 - val_mae: 0.5005\n",
      "Epoch 104/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6134 - mae: 0.5775 - val_loss: 0.4241 - val_mae: 0.5112\n",
      "Epoch 105/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6130 - mae: 0.5783 - val_loss: 0.4162 - val_mae: 0.5055\n",
      "Epoch 106/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6098 - mae: 0.5767 - val_loss: 0.4072 - val_mae: 0.5002\n",
      "Epoch 107/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6080 - mae: 0.5763 - val_loss: 0.4837 - val_mae: 0.5435\n",
      "Epoch 108/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6089 - mae: 0.5762 - val_loss: 0.4364 - val_mae: 0.5167\n",
      "Epoch 109/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6108 - mae: 0.5772 - val_loss: 0.5594 - val_mae: 0.5839\n",
      "Epoch 110/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6056 - mae: 0.5776 - val_loss: 0.4804 - val_mae: 0.5368\n",
      "Epoch 111/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6122 - mae: 0.5755 - val_loss: 0.4546 - val_mae: 0.5251\n",
      "Epoch 112/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6032 - mae: 0.5745 - val_loss: 0.4231 - val_mae: 0.5126\n",
      "Epoch 113/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6155 - mae: 0.5795 - val_loss: 0.4104 - val_mae: 0.5010\n",
      "Epoch 114/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6006 - mae: 0.5746 - val_loss: 0.4954 - val_mae: 0.5492\n",
      "Epoch 115/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6112 - mae: 0.5781 - val_loss: 0.3862 - val_mae: 0.4851\n",
      "Epoch 116/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6007 - mae: 0.5720 - val_loss: 0.4405 - val_mae: 0.5154\n",
      "Epoch 117/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6063 - mae: 0.5741 - val_loss: 0.4578 - val_mae: 0.5274\n",
      "Epoch 118/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.5903 - mae: 0.5682 - val_loss: 0.4419 - val_mae: 0.5229\n",
      "Epoch 119/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6086 - mae: 0.5741 - val_loss: 0.4531 - val_mae: 0.5289\n",
      "Epoch 120/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6076 - mae: 0.5762 - val_loss: 0.4229 - val_mae: 0.5109\n",
      "Epoch 121/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.5951 - mae: 0.5705 - val_loss: 0.5304 - val_mae: 0.5661\n",
      "Epoch 122/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6046 - mae: 0.5741 - val_loss: 0.4325 - val_mae: 0.5171\n",
      "Epoch 123/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6004 - mae: 0.5722 - val_loss: 0.4354 - val_mae: 0.5196\n",
      "Epoch 124/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6121 - mae: 0.5773 - val_loss: 0.4104 - val_mae: 0.5001\n",
      "Epoch 125/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.5949 - mae: 0.5701 - val_loss: 0.5009 - val_mae: 0.5514\n",
      "Epoch 126/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6045 - mae: 0.5745 - val_loss: 0.4314 - val_mae: 0.5167\n",
      "Epoch 127/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6102 - mae: 0.5769 - val_loss: 0.4186 - val_mae: 0.5067\n",
      "Epoch 128/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6091 - mae: 0.5771 - val_loss: 0.4735 - val_mae: 0.5393\n",
      "Epoch 129/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6004 - mae: 0.5740 - val_loss: 0.4130 - val_mae: 0.5035\n",
      "Epoch 130/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6206 - mae: 0.5789 - val_loss: 0.4089 - val_mae: 0.5018\n",
      "Epoch 131/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6089 - mae: 0.5760 - val_loss: 0.4249 - val_mae: 0.5093\n",
      "Epoch 132/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6390 - mae: 0.5796 - val_loss: 0.5084 - val_mae: 0.5567\n",
      "Epoch 133/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6066 - mae: 0.5742 - val_loss: 0.3966 - val_mae: 0.4906\n",
      "Epoch 134/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6098 - mae: 0.5760 - val_loss: 0.5117 - val_mae: 0.5564\n",
      "Epoch 135/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6040 - mae: 0.5744 - val_loss: 0.4149 - val_mae: 0.5025\n",
      "Epoch 136/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6076 - mae: 0.5738 - val_loss: 0.4558 - val_mae: 0.5235\n",
      "Epoch 137/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6011 - mae: 0.5706 - val_loss: 0.3880 - val_mae: 0.4863\n",
      "Epoch 138/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.5967 - mae: 0.5728 - val_loss: 0.4425 - val_mae: 0.5193\n",
      "Epoch 139/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6175 - mae: 0.5790 - val_loss: 0.4450 - val_mae: 0.5235\n",
      "Epoch 140/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.5982 - mae: 0.5712 - val_loss: 0.4043 - val_mae: 0.4927\n",
      "Epoch 141/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6054 - mae: 0.5717 - val_loss: 0.4618 - val_mae: 0.5352\n",
      "Epoch 142/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6070 - mae: 0.5735 - val_loss: 0.4652 - val_mae: 0.5340\n",
      "Epoch 143/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.5956 - mae: 0.5701 - val_loss: 0.3855 - val_mae: 0.4801\n",
      "Epoch 144/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.5897 - mae: 0.5693 - val_loss: 0.3849 - val_mae: 0.4781\n",
      "Epoch 145/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6013 - mae: 0.5724 - val_loss: 0.3809 - val_mae: 0.4829\n",
      "Epoch 146/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.5944 - mae: 0.5716 - val_loss: 0.4123 - val_mae: 0.5020\n",
      "Epoch 147/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.5975 - mae: 0.5716 - val_loss: 0.3807 - val_mae: 0.4810\n",
      "Epoch 148/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.5999 - mae: 0.5748 - val_loss: 0.4093 - val_mae: 0.4986\n",
      "Epoch 149/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6062 - mae: 0.5755 - val_loss: 0.4258 - val_mae: 0.5132\n",
      "Epoch 150/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.5980 - mae: 0.5723 - val_loss: 0.5125 - val_mae: 0.5640\n",
      "Epoch 151/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.5989 - mae: 0.5709 - val_loss: 0.4673 - val_mae: 0.5324\n",
      "Epoch 152/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6097 - mae: 0.5753 - val_loss: 0.4237 - val_mae: 0.5061\n",
      "Epoch 153/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.5996 - mae: 0.5716 - val_loss: 0.3953 - val_mae: 0.4935\n",
      "Epoch 154/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6001 - mae: 0.5732 - val_loss: 0.5244 - val_mae: 0.5672\n",
      "Epoch 155/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.5987 - mae: 0.5735 - val_loss: 0.4766 - val_mae: 0.5356\n",
      "Epoch 156/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.5972 - mae: 0.5713 - val_loss: 0.4667 - val_mae: 0.5330\n",
      "Epoch 157/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.5939 - mae: 0.5687 - val_loss: 0.3901 - val_mae: 0.4807\n",
      "Epoch 158/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6060 - mae: 0.5741 - val_loss: 0.4725 - val_mae: 0.5360\n",
      "Epoch 159/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6019 - mae: 0.5735 - val_loss: 0.5314 - val_mae: 0.5694\n",
      "Epoch 160/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.5968 - mae: 0.5706 - val_loss: 0.3515 - val_mae: 0.4612\n",
      "Epoch 161/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6025 - mae: 0.5728 - val_loss: 0.5011 - val_mae: 0.5495\n",
      "Epoch 162/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.5886 - mae: 0.5680 - val_loss: 0.3695 - val_mae: 0.4683\n",
      "Epoch 163/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6029 - mae: 0.5730 - val_loss: 0.3625 - val_mae: 0.4664\n",
      "Epoch 164/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.5899 - mae: 0.5705 - val_loss: 0.4943 - val_mae: 0.5484\n",
      "Epoch 165/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6037 - mae: 0.5738 - val_loss: 0.4544 - val_mae: 0.5280\n",
      "Epoch 166/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.5917 - mae: 0.5712 - val_loss: 0.4167 - val_mae: 0.5075\n",
      "Epoch 167/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.5923 - mae: 0.5697 - val_loss: 0.4235 - val_mae: 0.5120\n",
      "Epoch 168/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6041 - mae: 0.5733 - val_loss: 0.4336 - val_mae: 0.5138\n",
      "Epoch 169/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.5966 - mae: 0.5716 - val_loss: 0.4359 - val_mae: 0.5145\n",
      "Epoch 170/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.5983 - mae: 0.5721 - val_loss: 0.4432 - val_mae: 0.5194\n",
      "Epoch 171/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.5970 - mae: 0.5747 - val_loss: 0.4141 - val_mae: 0.5036\n",
      "Epoch 172/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.5964 - mae: 0.5696 - val_loss: 0.4023 - val_mae: 0.4982\n",
      "Epoch 173/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.5944 - mae: 0.5691 - val_loss: 0.4771 - val_mae: 0.5410\n",
      "Epoch 174/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.5950 - mae: 0.5702 - val_loss: 0.3904 - val_mae: 0.4908\n",
      "Epoch 175/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6001 - mae: 0.5717 - val_loss: 0.4172 - val_mae: 0.4933\n",
      "Epoch 176/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.5952 - mae: 0.5709 - val_loss: 0.4672 - val_mae: 0.5351\n",
      "Epoch 177/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6032 - mae: 0.5736 - val_loss: 0.5184 - val_mae: 0.5615\n",
      "Epoch 178/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6113 - mae: 0.5765 - val_loss: 0.4444 - val_mae: 0.5202\n",
      "Epoch 179/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.5953 - mae: 0.5704 - val_loss: 0.3492 - val_mae: 0.4564\n",
      "Epoch 180/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.5906 - mae: 0.5713 - val_loss: 0.4339 - val_mae: 0.5122\n",
      "Epoch 181/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6028 - mae: 0.5731 - val_loss: 0.4048 - val_mae: 0.4961\n",
      "Epoch 182/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.5955 - mae: 0.5714 - val_loss: 0.4388 - val_mae: 0.5161\n",
      "Epoch 183/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6054 - mae: 0.5745 - val_loss: 0.4979 - val_mae: 0.5482\n",
      "Epoch 184/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6071 - mae: 0.5740 - val_loss: 0.4325 - val_mae: 0.5131\n",
      "Epoch 185/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6021 - mae: 0.5745 - val_loss: 0.3581 - val_mae: 0.4671\n",
      "Epoch 186/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6090 - mae: 0.5760 - val_loss: 0.4719 - val_mae: 0.5346\n",
      "Epoch 187/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6096 - mae: 0.5760 - val_loss: 0.4632 - val_mae: 0.5344\n",
      "Epoch 188/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.5921 - mae: 0.5692 - val_loss: 0.4506 - val_mae: 0.5250\n",
      "Epoch 189/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5874 - mae: 0.5673 - val_loss: 0.5463 - val_mae: 0.5759\n",
      "Epoch 190/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6020 - mae: 0.5731 - val_loss: 0.4759 - val_mae: 0.5399\n",
      "Epoch 191/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.5912 - mae: 0.5671 - val_loss: 0.4253 - val_mae: 0.5126\n",
      "Epoch 192/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6023 - mae: 0.5723 - val_loss: 0.4550 - val_mae: 0.5212\n",
      "Epoch 193/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.5919 - mae: 0.5693 - val_loss: 0.4011 - val_mae: 0.4931\n",
      "Epoch 194/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.5950 - mae: 0.5708 - val_loss: 0.4273 - val_mae: 0.5094\n",
      "Epoch 195/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.5958 - mae: 0.5700 - val_loss: 0.4465 - val_mae: 0.5215\n",
      "Epoch 196/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.5996 - mae: 0.5706 - val_loss: 0.4359 - val_mae: 0.5125\n",
      "Epoch 197/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6014 - mae: 0.5721 - val_loss: 0.3831 - val_mae: 0.4826\n",
      "Epoch 198/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.5999 - mae: 0.5724 - val_loss: 0.3854 - val_mae: 0.4859\n",
      "Epoch 199/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.5839 - mae: 0.5691 - val_loss: 0.4783 - val_mae: 0.5405\n",
      "Epoch 200/200\n",
      "\u001b[1m3236/3236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6039 - mae: 0.5721 - val_loss: 0.5155 - val_mae: 0.5573\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_split=0.2,  # Use 20% of training data for validation\n",
    "    epochs=200,  # Number of epochs (adjust as needed)\n",
    "    batch_size=32,  # Batch size\n",
    "    verbose=1 , # Display training progress\n",
    "    callbacks=[tensorboard_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa1b101be39f5daa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T20:49:06.425908500Z",
     "start_time": "2024-12-26T20:49:04.178332Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2016/2016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 496us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c4c574add488773",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T20:49:08.725723500Z",
     "start_time": "2024-12-26T20:49:08.722413600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions_df = pd.DataFrame(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71b333248aa7be59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T20:49:10.419610700Z",
     "start_time": "2024-12-26T20:49:10.410196900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "column_from_df1 = df_test[\"Unnamed: 0\"]\n",
    "column_from_df2 = predictions_df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "207d7ab39242cd84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T20:49:11.324701400Z",
     "start_time": "2024-12-26T20:49:11.315733500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions_df = pd.concat([column_from_df1, column_from_df2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3363d337b3d8fec3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T20:49:12.037924900Z",
     "start_time": "2024-12-26T20:49:12.014428900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions_df.columns = ['id', 'target_feature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2cf96c0a943975ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T20:49:13.574466100Z",
     "start_time": "2024-12-26T20:49:13.562246500Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target_feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>8.156261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017</td>\n",
       "      <td>8.333298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018</td>\n",
       "      <td>8.710829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019</td>\n",
       "      <td>7.875579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>7.242989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64507</th>\n",
       "      <td>193531</td>\n",
       "      <td>5.773967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64508</th>\n",
       "      <td>193532</td>\n",
       "      <td>5.488265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64509</th>\n",
       "      <td>193533</td>\n",
       "      <td>5.438738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64510</th>\n",
       "      <td>193534</td>\n",
       "      <td>5.695416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64511</th>\n",
       "      <td>193535</td>\n",
       "      <td>5.708851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64512 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  target_feature\n",
       "0        2016        8.156261\n",
       "1        2017        8.333298\n",
       "2        2018        8.710829\n",
       "3        2019        7.875579\n",
       "4        2020        7.242989\n",
       "...       ...             ...\n",
       "64507  193531        5.773967\n",
       "64508  193532        5.488265\n",
       "64509  193533        5.438738\n",
       "64510  193534        5.695416\n",
       "64511  193535        5.708851\n",
       "\n",
       "[64512 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dde2bda3b8c7fbcb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T20:49:14.518681700Z",
     "start_time": "2024-12-26T20:49:14.515898800Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                  int64\n",
      "target_feature    float32\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(predictions_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b5905211f51fbdcb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T20:49:15.474591100Z",
     "start_time": "2024-12-26T20:49:15.446465100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(\"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9c328edf52ee3b1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T20:49:16.052757800Z",
     "start_time": "2024-12-26T20:49:16.041912300Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target_feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64507</th>\n",
       "      <td>193531</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64508</th>\n",
       "      <td>193532</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64509</th>\n",
       "      <td>193533</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64510</th>\n",
       "      <td>193534</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64511</th>\n",
       "      <td>193535</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64512 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  target_feature\n",
       "0        2016             5.0\n",
       "1        2017             5.0\n",
       "2        2018             5.0\n",
       "3        2019             5.0\n",
       "4        2020             5.0\n",
       "...       ...             ...\n",
       "64507  193531             5.0\n",
       "64508  193532             5.0\n",
       "64509  193533             5.0\n",
       "64510  193534             5.0\n",
       "64511  193535             5.0\n",
       "\n",
       "[64512 rows x 2 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a2f883791e565ab2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T20:49:17.438766300Z",
     "start_time": "2024-12-26T20:49:17.435834200Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                  int64\n",
      "target_feature    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(sample_submission.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1377d54064648d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T20:49:28.165893Z",
     "start_time": "2024-12-26T20:49:28.055070700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save submission as CSV file\n",
    "predictions_df.to_csv('D:\\\\Python\\\\Predict the wind speed at a wind turbine\\\\submissions\\\\oleg_bissing_submission_6.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
